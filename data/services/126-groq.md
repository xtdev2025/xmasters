---
id: 126
name: "Groq"
offerType: "FREE TIER"
type: "IA & Machine Learning"
category: "AI & ML"
url: "https://groq.com/"
summary: "Inference extremamente rápida gratuita. 14.500 tokens/segundo. Llama 3, Mixtral e Gemma."
tags: ["Ultra Rápido", "LPU", "Baixa Latência"]
badges:
  verified: true
  portugueseSupport: false
  noCreditCard: true
  established: 2016
---

Groq revoluciona inference de LLMs com sua arquitetura LPU (Language Processing Unit), alcançando velocidades de até 14.500 tokens por segundo - muito mais rápido que GPUs tradicionais. Free tier generoso permite experimentar a velocidade incomparável com modelos open-source.

## Recursos Principais

- Free tier com rate limits generosos
- Velocidade recorde de inference (14.500 tokens/s)
- Llama 3, Mixtral 8x7B, Gemma
- Latência ultra-baixa
- API compatível com OpenAI
- Ideal para aplicações real-time
- GroqCloud platform
- Arquitetura LPU proprietária
